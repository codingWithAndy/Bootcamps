{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, GRU\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 8\n",
    "D = 2\n",
    "M = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(1, T, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm1():\n",
    "  input_ = Input(shape=(T, D))\n",
    "  rnn = LSTM(M, return_state=True)\n",
    "  x = rnn(input_)\n",
    "\n",
    "  model = Model(inputs=input_, outputs=x)\n",
    "  o, h, c = model.predict(X)\n",
    "  print(\"o:\", o)\n",
    "  print(\"h:\", h)\n",
    "  print(\"c:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm2():\n",
    "  input_ = Input(shape=(T, D))\n",
    "  rnn = LSTM(M, return_state=True, return_sequences=True)\n",
    "  # rnn = GRU(M, return_state=True)\n",
    "  x = rnn(input_)\n",
    "\n",
    "  model = Model(inputs=input_, outputs=x)\n",
    "  o, h, c = model.predict(X)\n",
    "  print(\"o:\", o)\n",
    "  print(\"h:\", h)\n",
    "  print(\"c:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru1():\n",
    "  input_ = Input(shape=(T, D))\n",
    "  rnn = GRU(M, return_state=True)\n",
    "  x = rnn(input_)\n",
    "\n",
    "  model = Model(inputs=input_, outputs=x)\n",
    "  o, h = model.predict(X)\n",
    "  print(\"o:\", o)\n",
    "  print(\"h:\", h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru2():\n",
    "  input_ = Input(shape=(T, D))\n",
    "  rnn = GRU(M, return_state=True, return_sequences=True)\n",
    "  x = rnn(input_)\n",
    "\n",
    "  model = Model(inputs=input_, outputs=x)\n",
    "  o, h = model.predict(X)\n",
    "  print(\"o:\", o)\n",
    "  print(\"h:\", h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm1:\n",
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 21:20:59.764560: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-27 21:20:59.764671: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-03-27 21:21:00.013476: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-27 21:21:00.134828: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-27 21:21:00.196458: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o: [[-0.01730855 -0.00057424 -0.08383728]]\n",
      "h: [[-0.01730855 -0.00057424 -0.08383728]]\n",
      "c: [[-0.04033358 -0.00105233 -0.15887207]]\n",
      "lstm2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 21:21:01.303779: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-27 21:21:01.338403: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o: [[[-0.01351425 -0.00506733 -0.00709051]\n",
      "  [ 0.15516324 -0.07690861  0.03553857]\n",
      "  [ 0.11953814 -0.11037374  0.03495307]\n",
      "  [ 0.18413112 -0.13413958  0.0503289 ]\n",
      "  [ 0.06568261 -0.17850454  0.00124175]\n",
      "  [ 0.07041039 -0.11754791 -0.01166848]\n",
      "  [ 0.03864627 -0.03862643 -0.04289687]\n",
      "  [-0.00520942 -0.00696062 -0.06924865]]]\n",
      "h: [[-0.00520942 -0.00696062 -0.06924865]]\n",
      "c: [[-0.0126809  -0.0127945  -0.13105206]]\n",
      "gru1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 21:21:01.672968: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-27 21:21:01.701612: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o: [[ 0.372872    0.45077613 -0.23971158]]\n",
      "h: [[ 0.372872    0.45077613 -0.23971158]]\n",
      "gru2:\n",
      "o: [[[ 0.1795511   0.16171902 -0.10687837]\n",
      "  [-0.17159446 -0.10205083  0.10894652]\n",
      "  [ 0.07751743  0.10065709 -0.03057584]\n",
      "  [ 0.02764704  0.05535852 -0.05139613]\n",
      "  [ 0.5498217   0.49494976 -0.46695158]\n",
      "  [ 0.4200687   0.3354839  -0.4303531 ]\n",
      "  [ 0.15212414  0.06758367 -0.2839322 ]\n",
      "  [ 0.32954592  0.21946062 -0.2996341 ]]]\n",
      "h: [[ 0.32954592  0.21946062 -0.2996341 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 21:21:02.153555: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-27 21:21:02.184183: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "print(\"lstm1:\")\n",
    "lstm1()\n",
    "print(\"lstm2:\")\n",
    "lstm2()\n",
    "print(\"gru1:\")\n",
    "gru1()\n",
    "print(\"gru2:\")\n",
    "gru2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
